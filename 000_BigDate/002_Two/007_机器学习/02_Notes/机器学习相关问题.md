# 机器学习相关问题

## A1 线性回归

predicted：预测

线性回归中代价函数为： 
 ![image-20210409110022058](C:%5CUsers%5CLenovo%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210409110022058.png)

开始为何是除以2*m*

，第一反应不应该除以*m*么？在吴恩达机器学习视频公开课上讲解是为了其他数学计算的方便。其实这里无论除以2*m*还是*m*，代价函数最优化的结果*θ* 都是相同的。

数学计算的方便：之后利用梯度下降法对*J*求导，如果是2*m*，求导结果为：

![image-20210409110051457](C:%5CUsers%5CLenovo%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210409110051457.png)

，这里正好除以m，便于计算。

## A2 机器学习数据格式

libsvm

目标值 下标（Index）: value

1 1:58 2:0 3:4

## A3 spark中依赖

mllib

## A4 两种向量

Vector

dense稠密的

[所有书数]

sparse稀疏的

(目标数量，[有数据的位置数组]，[相对应的数据])

![image-20210409115051851](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98.assets/image-20210409115051851.png)

## A5 标记点

![image-20210409115342383](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98.assets/image-20210409115342383.png)

## A6 读取向量基数据

![image-20210409115556143](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98.assets/image-20210409115556143.png)

## A7 spark指南

选数据

选算法

模型

http://spark.apache.org/docs/2.4.6/ml-guide.html

## A8 贝叶斯

利用概率来分类的

## A9 关联关系

 
$$
support（X）=
$$
x->y

y->x

这两者置信度可以看出放一起的效率

## A10 Aprori

关注的是频繁项集（筛选掉一部分）

全量操作



spark和Scala没有

Python有

## A11 树形结构（数据压缩）

FP-growth

![image-20210410105946953](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98.assets/image-20210410105946953.png)

1. 数据
2. 算法
3. 配置模型参数
   1. ![image-20210410110346902](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98.assets/image-20210410110346902.png)
4. 查看/评估模型
5. 操作

![image-20210410110705508](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98.assets/image-20210410110705508.png)

## A12 混淆矩阵



![image-20210410163639373](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98.assets/image-20210410163639373.png)

和医生有关

ROC：曲线

AUC：面积越大越好，顶值1